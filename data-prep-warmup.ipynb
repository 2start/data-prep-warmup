{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rawDeathCauses: org.apache.spark.sql.DataFrame = [Year: string, 113 Cause Name: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rawDeathCauses = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .load(\"/home/start2/git/data-prep-warmup/src/main/resources/death_causes_usa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------------------------------------+----------------------+-------+------+-----------------------+\n",
      "|Year|113 Cause Name                                      |Cause Name            |State  |Deaths|Age-adjusted Death Rate|\n",
      "+----+----------------------------------------------------+----------------------+-------+------+-----------------------+\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Unintentional injuries|Alabama|2755  |55.50                  |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Unintentional injuries|Alaska |439   |63.10                  |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Unintentional injuries|Arizona|4010  |54.20                  |\n",
      "+----+----------------------------------------------------+----------------------+-------+------+-----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawDeathCauses.show(3, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataset: 10296\n",
      "Number of rows in column reduced dataset: 10296\n",
      "+----+----------------------------------------------------+--------------------+------+\n",
      "|Year|113 Cause Name                                      |State               |Deaths|\n",
      "+----+----------------------------------------------------+--------------------+------+\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Alabama             |2755  |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Alaska              |439   |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Arizona             |4010  |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Arkansas            |1604  |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|California          |13213 |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Colorado            |2880  |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Connecticut         |1978  |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Delaware            |516   |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|District of Columbia|401   |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Florida             |12561 |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Georgia             |4701  |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Hawaii              |577   |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Idaho               |849   |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Illinois            |5508  |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Indiana             |3496  |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Iowa                |1608  |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Kansas              |1444  |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Kentucky            |3194  |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Louisiana           |2710  |\n",
      "|2016|Accidents (unintentional injuries) (V01-X59,Y85-Y86)|Maine               |909   |\n",
      "+----+----------------------------------------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "states: List[String] = List(Alabama, Alaska, Arizona, Arkansas, California, Colorado, Connecticut, Delaware, District of Columbia, Florida, Georgia, Hawaii, Idaho, Illinois, Indiana, Iowa, Kansas, Kentucky, Louisiana, Maine, Montana, Nebraska, Nevada, New Hampshire, New Jersey, New Mexico, New York, North Carolina, North Dakota, Ohio, Oklahoma, Oregon, Maryland, Massachusetts, Michigan, Minnesota, Mississippi, Missouri, Pennsylvania, Rhode Island, South Carolina, South Dakota, Tennessee, Texas, Utah, Vermont, Virginia, Washington, West Virginia, Wisconsin, Wyoming)\n",
       "columnReducedDeathCauses: org.apache.spark.sql.DataFrame = [Year: string, 113 Cause Name: string ... 2 more fields]\n",
       "reducedDeathCauses: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Year: string, 113 Cause Name: s..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val states = List(\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\", \"District of Columbia\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\")\n",
    "val columnReducedDeathCauses = rawDeathCauses\n",
    "    .drop(\"Cause Name\")\n",
    "    .drop(\"Age-adjusted Death Rate\")\n",
    "\n",
    "\n",
    "\n",
    "val reducedDeathCauses = columnReducedDeathCauses\n",
    "    .filter(col(\"State\").isin(states:_*))\n",
    "\n",
    "println(\"Number of rows in dataset: \" + columnReducedDeathCauses.count)\n",
    "println(\"Number of rows in column reduced dataset: \" + columnReducedDeathCauses.count)\n",
    "\n",
    "\n",
    "columnCleanedDeathCauses.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: string (nullable = true)\n",
      " |-- 113 Cause Name: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Deaths: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columnCleanedDeathCauses.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Death Cause: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deathCauses: org.apache.spark.sql.DataFrame = [Year: int, Death Cause: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val deathCauses = columnCleanedDeathCauses\n",
    "    .withColumn(\"Deaths\", $\"Deaths\".cast(\"Int\"))\n",
    "    .withColumn(\"Year\", $\"Year\".cast(\"Int\"))\n",
    "    .withColumnRenamed(\"113 Cause Name\", \"Death Cause\")\n",
    "\n",
    "deathCauses.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SUMLEV: string (nullable = true)\n",
      " |-- REGION: string (nullable = true)\n",
      " |-- DIVISION: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- ESTIMATESBASE2010: string (nullable = true)\n",
      " |-- POPESTIMATE2010: string (nullable = true)\n",
      " |-- POPESTIMATE2011: string (nullable = true)\n",
      " |-- POPESTIMATE2012: string (nullable = true)\n",
      " |-- POPESTIMATE2013: string (nullable = true)\n",
      " |-- POPESTIMATE2014: string (nullable = true)\n",
      " |-- POPESTIMATE2015: string (nullable = true)\n",
      " |-- POPESTIMATE2016: string (nullable = true)\n",
      " |-- POPESTIMATE2017: string (nullable = true)\n",
      " |-- NPOPCHG_2010: string (nullable = true)\n",
      " |-- NPOPCHG_2011: string (nullable = true)\n",
      " |-- NPOPCHG_2012: string (nullable = true)\n",
      " |-- NPOPCHG_2013: string (nullable = true)\n",
      " |-- NPOPCHG_2014: string (nullable = true)\n",
      " |-- NPOPCHG_2015: string (nullable = true)\n",
      " |-- NPOPCHG_2016: string (nullable = true)\n",
      " |-- NPOPCHG_2017: string (nullable = true)\n",
      " |-- PPOPCHG_2010: string (nullable = true)\n",
      " |-- PPOPCHG_2011: string (nullable = true)\n",
      " |-- PPOPCHG_2012: string (nullable = true)\n",
      " |-- PPOPCHG_2013: string (nullable = true)\n",
      " |-- PPOPCHG_2014: string (nullable = true)\n",
      " |-- PPOPCHG_2015: string (nullable = true)\n",
      " |-- PPOPCHG_2016: string (nullable = true)\n",
      " |-- PPOPCHG_2017: string (nullable = true)\n",
      " |-- NRANK_ESTBASE2010: string (nullable = true)\n",
      " |-- NRANK_POPEST2010: string (nullable = true)\n",
      " |-- NRANK_POPEST2011: string (nullable = true)\n",
      " |-- NRANK_POPEST2012: string (nullable = true)\n",
      " |-- NRANK_POPEST2013: string (nullable = true)\n",
      " |-- NRANK_POPEST2014: string (nullable = true)\n",
      " |-- NRANK_POPEST2015: string (nullable = true)\n",
      " |-- NRANK_POPEST2016: string (nullable = true)\n",
      " |-- NRANK_POPEST2017: string (nullable = true)\n",
      " |-- NRANK_NPCHG2010: string (nullable = true)\n",
      " |-- NRANK_NPCHG2011: string (nullable = true)\n",
      " |-- NRANK_NPCHG2012: string (nullable = true)\n",
      " |-- NRANK_NPCHG2013: string (nullable = true)\n",
      " |-- NRANK_NPCHG2014: string (nullable = true)\n",
      " |-- NRANK_NPCHG2015: string (nullable = true)\n",
      " |-- NRANK_NPCHG2016: string (nullable = true)\n",
      " |-- NRANK_NPCHG2017: string (nullable = true)\n",
      " |-- NRANK_PPCHG2010: string (nullable = true)\n",
      " |-- NRANK_PPCHG2011: string (nullable = true)\n",
      " |-- NRANK_PPCHG2012: string (nullable = true)\n",
      " |-- NRANK_PPCHG2013: string (nullable = true)\n",
      " |-- NRANK_PPCHG2014: string (nullable = true)\n",
      " |-- NRANK_PPCHG2015: string (nullable = true)\n",
      " |-- NRANK_PPCHG2016: string (nullable = true)\n",
      " |-- NRANK_PPCHG2017: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "censusSecondDecade: org.apache.spark.sql.DataFrame = [SUMLEV: string, REGION: string ... 53 more fields]\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val censusSecondDecade = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .load(\"/home/start2/git/data-prep-warmup/src/main/resources/census_2010_2017.csv\")\n",
    "\n",
    "censusSecondDecade.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statePopEst: org.apache.spark.sql.DataFrame = [NAME: string, POPESTIMATE2010: string ... 7 more fields]\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val statePopEst = censusSecondDecade.select(\n",
    "    \"NAME\",\n",
    "    \"POPESTIMATE2010\",\n",
    "    \"POPESTIMATE2011\",\n",
    "    \"POPESTIMATE2012\",\n",
    "    \"POPESTIMATE2013\",\n",
    "    \"POPESTIMATE2014\",\n",
    "    \"POPESTIMATE2015\",\n",
    "    \"POPESTIMATE2016\",\n",
    "    \"POPESTIMATE2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states in census 2010-2017 dataset: 50"
     ]
    },
    {
     "data": {
      "text/plain": [
       "reducedStatePopEst: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [NAME: string, POPESTIMATE2010: string ... 7 more fields]\n"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val reducedStatePopEst = statePopEst.filter(col(\"NAME\").isin(states:_*))\n",
    "print(\"Number of states in census 2010-2017 dataset: \" + (filteredStatePopEst.count()-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- POPESTIMATE2010: string (nullable = true)\n",
      " |-- POPESTIMATE2011: string (nullable = true)\n",
      " |-- POPESTIMATE2012: string (nullable = true)\n",
      " |-- POPESTIMATE2013: string (nullable = true)\n",
      " |-- POPESTIMATE2014: string (nullable = true)\n",
      " |-- POPESTIMATE2015: string (nullable = true)\n",
      " |-- POPESTIMATE2016: string (nullable = true)\n",
      " |-- POPESTIMATE2017: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reducedStatePopEst.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State: string (nullable = true)\n",
      " |-- Population: integer (nullable = true)\n",
      " |-- Year: integer (nullable = false)\n",
      "\n",
      "+--------------------+----------+----+\n",
      "|               State|Population|Year|\n",
      "+--------------------+----------+----+\n",
      "|             Alabama|   4785579|2010|\n",
      "|              Alaska|    714015|2010|\n",
      "|             Arizona|   6407002|2010|\n",
      "|            Arkansas|   2921737|2010|\n",
      "|          California|  37327690|2010|\n",
      "|            Colorado|   5048029|2010|\n",
      "|         Connecticut|   3580171|2010|\n",
      "|            Delaware|    899712|2010|\n",
      "|District of Columbia|    605040|2010|\n",
      "|             Florida|  18846461|2010|\n",
      "|             Georgia|   9712696|2010|\n",
      "|              Hawaii|   1363817|2010|\n",
      "|               Idaho|   1570912|2010|\n",
      "|            Illinois|  12841196|2010|\n",
      "|             Indiana|   6490029|2010|\n",
      "|                Iowa|   3050223|2010|\n",
      "|              Kansas|   2858403|2010|\n",
      "|            Kentucky|   4347948|2010|\n",
      "|           Louisiana|   4544871|2010|\n",
      "|               Maine|   1327568|2010|\n",
      "+--------------------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pop2010: org.apache.spark.sql.DataFrame = [NAME: string, Population: string ... 1 more field]\n",
       "pop2011: org.apache.spark.sql.DataFrame = [NAME: string, Population: string ... 1 more field]\n",
       "pop2012: org.apache.spark.sql.DataFrame = [NAME: string, Population: string ... 1 more field]\n",
       "pop2013: org.apache.spark.sql.DataFrame = [NAME: string, Population: string ... 1 more field]\n",
       "pop2014: org.apache.spark.sql.DataFrame = [NAME: string, Population: string ... 1 more field]\n",
       "pop2015: org.apache.spark.sql.DataFrame = [NAME: string, Population: string ... 1 more field]\n",
       "pop2016: org.apache.spark.sql.DataFrame = [NAME: string, Population: string ... 1 more field]\n",
       "pop2017: org.apache.spark.sql.DataFrame = [NAME: string, Population: string ... 1 more field]\n",
       "popPerYear: org.apache.spark.sql.DataFrame = ..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pop2010 = reducedStatePopEst.select(\"NAME\", \"POPESTIMATE2010\")\n",
    "    .withColumnRenamed(\"POPESTIMATE2010\", \"Population\")\n",
    "    .withColumn(\"Year\", lit(2010))\n",
    "val pop2011 = reducedStatePopEst.select(\"NAME\", \"POPESTIMATE2011\")\n",
    "    .withColumnRenamed(\"POPESTIMATE2011\", \"Population\")\n",
    "    .withColumn(\"Year\", lit(2011))\n",
    "val pop2012 = reducedStatePopEst.select(\"NAME\", \"POPESTIMATE2012\")\n",
    "    .withColumnRenamed(\"POPESTIMATE2012\", \"Population\")\n",
    "    .withColumn(\"Year\", lit(2012))\n",
    "val pop2013 = reducedStatePopEst.select(\"NAME\", \"POPESTIMATE2013\")\n",
    "    .withColumnRenamed(\"POPESTIMATE2013\", \"Population\")\n",
    "    .withColumn(\"Year\", lit(2013))\n",
    "val pop2014 = reducedStatePopEst.select(\"NAME\", \"POPESTIMATE2014\")\n",
    "    .withColumnRenamed(\"POPESTIMATE2014\", \"Population\")\n",
    "    .withColumn(\"Year\", lit(2014))\n",
    "val pop2015 = reducedStatePopEst.select(\"NAME\", \"POPESTIMATE2015\")\n",
    "    .withColumnRenamed(\"POPESTIMATE2015\", \"Population\")   \n",
    "    .withColumn(\"Year\", lit(2015))\n",
    "val pop2016 = reducedStatePopEst.select(\"NAME\", \"POPESTIMATE2016\")\n",
    "    .withColumnRenamed(\"POPESTIMATE2016\", \"Population\")\n",
    "    .withColumn(\"Year\", lit(2016))\n",
    "val pop2017 = reducedStatePopEst.select(\"NAME\", \"POPESTIMATE2017\")\n",
    "    .withColumnRenamed(\"POPESTIMATE2017\", \"Population\")\n",
    "    .withColumn(\"Year\", lit(2017))\n",
    "\n",
    "val popPerYear = List(pop2010, pop2011, pop2012, pop2013, pop2014, pop2015, pop2016, pop2017)\n",
    "    .map(df => {\n",
    "        df.withColumn(\"Population\", $\"population\".cast(\"Int\"))\n",
    "    })\n",
    "    .reduce((df1, df2) => df1.union(df2))\n",
    "    .withColumnRenamed(\"NAME\",\"State\")\n",
    "\n",
    "popPerYear.printSchema\n",
    "popPerYear.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+------+\n",
      "|Year|         Death Cause|               State|Deaths|\n",
      "+----+--------------------+--------------------+------+\n",
      "|2016|Accidents (uninte...|             Alabama|  2755|\n",
      "|2016|Accidents (uninte...|              Alaska|   439|\n",
      "|2016|Accidents (uninte...|             Arizona|  4010|\n",
      "|2016|Accidents (uninte...|            Arkansas|  1604|\n",
      "|2016|Accidents (uninte...|          California| 13213|\n",
      "|2016|Accidents (uninte...|            Colorado|  2880|\n",
      "|2016|Accidents (uninte...|         Connecticut|  1978|\n",
      "|2016|Accidents (uninte...|            Delaware|   516|\n",
      "|2016|Accidents (uninte...|District of Columbia|   401|\n",
      "|2016|Accidents (uninte...|             Florida| 12561|\n",
      "|2016|Accidents (uninte...|             Georgia|  4701|\n",
      "|2016|Accidents (uninte...|              Hawaii|   577|\n",
      "|2016|Accidents (uninte...|               Idaho|   849|\n",
      "|2016|Accidents (uninte...|            Illinois|  5508|\n",
      "|2016|Accidents (uninte...|             Indiana|  3496|\n",
      "|2016|Accidents (uninte...|                Iowa|  1608|\n",
      "|2016|Accidents (uninte...|              Kansas|  1444|\n",
      "|2016|Accidents (uninte...|            Kentucky|  3194|\n",
      "|2016|Accidents (uninte...|           Louisiana|  2710|\n",
      "|2016|Accidents (uninte...|               Maine|   909|\n",
      "+----+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deathCauses.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deathCausesPerStateYear: org.apache.spark.sql.DataFrame = [Year: int, State: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val deathCausesPerStateYear = popPerYear.join(deathCauses, Seq(\"Year\",\"State\"), \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+----------+--------------------+------+\n",
      "|Year|               State|Population|         Death Cause|Deaths|\n",
      "+----+--------------------+----------+--------------------+------+\n",
      "|2016|             Alabama|   4860545|Accidents (uninte...|  2755|\n",
      "|2016|              Alaska|    741522|Accidents (uninte...|   439|\n",
      "|2016|             Arizona|   6908642|Accidents (uninte...|  4010|\n",
      "|2016|            Arkansas|   2988231|Accidents (uninte...|  1604|\n",
      "|2016|          California|  39296476|Accidents (uninte...| 13213|\n",
      "|2016|            Colorado|   5530105|Accidents (uninte...|  2880|\n",
      "|2016|         Connecticut|   3587685|Accidents (uninte...|  1978|\n",
      "|2016|            Delaware|    952698|Accidents (uninte...|   516|\n",
      "|2016|District of Columbia|    684336|Accidents (uninte...|   401|\n",
      "|2016|             Florida|  20656589|Accidents (uninte...| 12561|\n",
      "|2016|             Georgia|  10313620|Accidents (uninte...|  4701|\n",
      "|2016|              Hawaii|   1428683|Accidents (uninte...|   577|\n",
      "|2016|               Idaho|   1680026|Accidents (uninte...|   849|\n",
      "|2016|            Illinois|  12835726|Accidents (uninte...|  5508|\n",
      "|2016|             Indiana|   6634007|Accidents (uninte...|  3496|\n",
      "|2016|                Iowa|   3130869|Accidents (uninte...|  1608|\n",
      "|2016|              Kansas|   2907731|Accidents (uninte...|  1444|\n",
      "|2016|            Kentucky|   4436113|Accidents (uninte...|  3194|\n",
      "|2016|           Louisiana|   4686157|Accidents (uninte...|  2710|\n",
      "|2016|               Maine|   1330232|Accidents (uninte...|   909|\n",
      "+----+--------------------+----------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deathCausesPerStateYear.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

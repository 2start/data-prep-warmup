{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim: Put death rates in different US states into perspective to the state's population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://start2-pc.local:4040\n",
       "SparkContext available as 'sc' (version = 2.3.2, master = local[*], app id = local-1541429835871)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "rawDeathCauses: org.apache.spark.sql.DataFrame = [Year: string, 113 Cause Name: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rawDeathCauses = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .load(\"death_causes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+-------+------+-----------------------+\n",
      "|Year|      113 Cause Name|          Cause Name|  State|Deaths|Age-adjusted Death Rate|\n",
      "+----+--------------------+--------------------+-------+------+-----------------------+\n",
      "|2016|Accidents (uninte...|Unintentional inj...|Alabama|  2755|                  55.50|\n",
      "|2016|Accidents (uninte...|Unintentional inj...| Alaska|   439|                  63.10|\n",
      "|2016|Accidents (uninte...|Unintentional inj...|Arizona|  4010|                  54.20|\n",
      "+----+--------------------+--------------------+-------+------+-----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawDeathCauses.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary and redundant information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "columnReducedDeathCauses: org.apache.spark.sql.DataFrame = [Year: string, 113 Cause Name: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val columnReducedDeathCauses = rawDeathCauses\n",
    "    .drop(\"Cause Name\")\n",
    "    .drop(\"Age-adjusted Death Rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: string (nullable = true)\n",
      " |-- 113 Cause Name: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Deaths: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columnReducedDeathCauses.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast the deaths and year to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deathCauses: org.apache.spark.sql.DataFrame = [Year: int, Death Cause: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val deathCauses = columnReducedDeathCauses\n",
    "    .withColumn(\"Deaths\", $\"Deaths\".cast(\"Int\"))\n",
    "    .withColumn(\"Year\", $\"Year\".cast(\"Int\"))\n",
    "    .withColumnRenamed(\"113 Cause Name\", \"Death Cause\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Death Cause: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Deaths: integer (nullable = true)\n",
      "\n",
      "+----+--------------------+-------+------+\n",
      "|Year|         Death Cause|  State|Deaths|\n",
      "+----+--------------------+-------+------+\n",
      "|2016|Accidents (uninte...|Alabama|  2755|\n",
      "|2016|Accidents (uninte...| Alaska|   439|\n",
      "|2016|Accidents (uninte...|Arizona|  4010|\n",
      "+----+--------------------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deathCauses.printSchema\n",
    "deathCauses.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the census dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "censusSecondDecade: org.apache.spark.sql.DataFrame = [SUMLEV: string, REGION: string ... 119 more fields]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val censusSecondDecade = spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .load(\"census.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SUMLEV: string (nullable = true)\n",
      " |-- REGION: string (nullable = true)\n",
      " |-- DIVISION: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- CENSUS2010POP: string (nullable = true)\n",
      " |-- ESTIMATESBASE2010: string (nullable = true)\n",
      " |-- POPESTIMATE2010: string (nullable = true)\n",
      " |-- POPESTIMATE2011: string (nullable = true)\n",
      " |-- POPESTIMATE2012: string (nullable = true)\n",
      " |-- POPESTIMATE2013: string (nullable = true)\n",
      " |-- POPESTIMATE2014: string (nullable = true)\n",
      " |-- POPESTIMATE2015: string (nullable = true)\n",
      " |-- POPESTIMATE2016: string (nullable = true)\n",
      " |-- POPESTIMATE2017: string (nullable = true)\n",
      " |-- NPOPCHG_2010: string (nullable = true)\n",
      " |-- NPOPCHG_2011: string (nullable = true)\n",
      " |-- NPOPCHG_2012: string (nullable = true)\n",
      " |-- NPOPCHG_2013: string (nullable = true)\n",
      " |-- NPOPCHG_2014: string (nullable = true)\n",
      " |-- NPOPCHG_2015: string (nullable = true)\n",
      " |-- NPOPCHG_2016: string (nullable = true)\n",
      " |-- NPOPCHG_2017: string (nullable = true)\n",
      " |-- BIRTHS2010: string (nullable = true)\n",
      " |-- BIRTHS2011: string (nullable = true)\n",
      " |-- BIRTHS2012: string (nullable = true)\n",
      " |-- BIRTHS2013: string (nullable = true)\n",
      " |-- BIRTHS2014: string (nullable = true)\n",
      " |-- BIRTHS2015: string (nullable = true)\n",
      " |-- BIRTHS2016: string (nullable = true)\n",
      " |-- BIRTHS2017: string (nullable = true)\n",
      " |-- DEATHS2010: string (nullable = true)\n",
      " |-- DEATHS2011: string (nullable = true)\n",
      " |-- DEATHS2012: string (nullable = true)\n",
      " |-- DEATHS2013: string (nullable = true)\n",
      " |-- DEATHS2014: string (nullable = true)\n",
      " |-- DEATHS2015: string (nullable = true)\n",
      " |-- DEATHS2016: string (nullable = true)\n",
      " |-- DEATHS2017: string (nullable = true)\n",
      " |-- NATURALINC2010: string (nullable = true)\n",
      " |-- NATURALINC2011: string (nullable = true)\n",
      " |-- NATURALINC2012: string (nullable = true)\n",
      " |-- NATURALINC2013: string (nullable = true)\n",
      " |-- NATURALINC2014: string (nullable = true)\n",
      " |-- NATURALINC2015: string (nullable = true)\n",
      " |-- NATURALINC2016: string (nullable = true)\n",
      " |-- NATURALINC2017: string (nullable = true)\n",
      " |-- INTERNATIONALMIG2010: string (nullable = true)\n",
      " |-- INTERNATIONALMIG2011: string (nullable = true)\n",
      " |-- INTERNATIONALMIG2012: string (nullable = true)\n",
      " |-- INTERNATIONALMIG2013: string (nullable = true)\n",
      " |-- INTERNATIONALMIG2014: string (nullable = true)\n",
      " |-- INTERNATIONALMIG2015: string (nullable = true)\n",
      " |-- INTERNATIONALMIG2016: string (nullable = true)\n",
      " |-- INTERNATIONALMIG2017: string (nullable = true)\n",
      " |-- DOMESTICMIG2010: string (nullable = true)\n",
      " |-- DOMESTICMIG2011: string (nullable = true)\n",
      " |-- DOMESTICMIG2012: string (nullable = true)\n",
      " |-- DOMESTICMIG2013: string (nullable = true)\n",
      " |-- DOMESTICMIG2014: string (nullable = true)\n",
      " |-- DOMESTICMIG2015: string (nullable = true)\n",
      " |-- DOMESTICMIG2016: string (nullable = true)\n",
      " |-- DOMESTICMIG2017: string (nullable = true)\n",
      " |-- NETMIG2010: string (nullable = true)\n",
      " |-- NETMIG2011: string (nullable = true)\n",
      " |-- NETMIG2012: string (nullable = true)\n",
      " |-- NETMIG2013: string (nullable = true)\n",
      " |-- NETMIG2014: string (nullable = true)\n",
      " |-- NETMIG2015: string (nullable = true)\n",
      " |-- NETMIG2016: string (nullable = true)\n",
      " |-- NETMIG2017: string (nullable = true)\n",
      " |-- RESIDUAL2010: string (nullable = true)\n",
      " |-- RESIDUAL2011: string (nullable = true)\n",
      " |-- RESIDUAL2012: string (nullable = true)\n",
      " |-- RESIDUAL2013: string (nullable = true)\n",
      " |-- RESIDUAL2014: string (nullable = true)\n",
      " |-- RESIDUAL2015: string (nullable = true)\n",
      " |-- RESIDUAL2016: string (nullable = true)\n",
      " |-- RESIDUAL2017: string (nullable = true)\n",
      " |-- RBIRTH2011: string (nullable = true)\n",
      " |-- RBIRTH2012: string (nullable = true)\n",
      " |-- RBIRTH2013: string (nullable = true)\n",
      " |-- RBIRTH2014: string (nullable = true)\n",
      " |-- RBIRTH2015: string (nullable = true)\n",
      " |-- RBIRTH2016: string (nullable = true)\n",
      " |-- RBIRTH2017: string (nullable = true)\n",
      " |-- RDEATH2011: string (nullable = true)\n",
      " |-- RDEATH2012: string (nullable = true)\n",
      " |-- RDEATH2013: string (nullable = true)\n",
      " |-- RDEATH2014: string (nullable = true)\n",
      " |-- RDEATH2015: string (nullable = true)\n",
      " |-- RDEATH2016: string (nullable = true)\n",
      " |-- RDEATH2017: string (nullable = true)\n",
      " |-- RNATURALINC2011: string (nullable = true)\n",
      " |-- RNATURALINC2012: string (nullable = true)\n",
      " |-- RNATURALINC2013: string (nullable = true)\n",
      " |-- RNATURALINC2014: string (nullable = true)\n",
      " |-- RNATURALINC2015: string (nullable = true)\n",
      " |-- RNATURALINC2016: string (nullable = true)\n",
      " |-- RNATURALINC2017: string (nullable = true)\n",
      " |-- RINTERNATIONALMIG2011: string (nullable = true)\n",
      " |-- RINTERNATIONALMIG2012: string (nullable = true)\n",
      " |-- RINTERNATIONALMIG2013: string (nullable = true)\n",
      " |-- RINTERNATIONALMIG2014: string (nullable = true)\n",
      " |-- RINTERNATIONALMIG2015: string (nullable = true)\n",
      " |-- RINTERNATIONALMIG2016: string (nullable = true)\n",
      " |-- RINTERNATIONALMIG2017: string (nullable = true)\n",
      " |-- RDOMESTICMIG2011: string (nullable = true)\n",
      " |-- RDOMESTICMIG2012: string (nullable = true)\n",
      " |-- RDOMESTICMIG2013: string (nullable = true)\n",
      " |-- RDOMESTICMIG2014: string (nullable = true)\n",
      " |-- RDOMESTICMIG2015: string (nullable = true)\n",
      " |-- RDOMESTICMIG2016: string (nullable = true)\n",
      " |-- RDOMESTICMIG2017: string (nullable = true)\n",
      " |-- RNETMIG2011: string (nullable = true)\n",
      " |-- RNETMIG2012: string (nullable = true)\n",
      " |-- RNETMIG2013: string (nullable = true)\n",
      " |-- RNETMIG2014: string (nullable = true)\n",
      " |-- RNETMIG2015: string (nullable = true)\n",
      " |-- RNETMIG2016: string (nullable = true)\n",
      " |-- RNETMIG2017: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "censusSecondDecade.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The state name is contained in the name column and not in the state column.\n",
    "\n",
    "### Select information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "statePopEst: org.apache.spark.sql.DataFrame = [NAME: string, REGION: string ... 9 more fields]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val statePopEst = censusSecondDecade.select(\n",
    "    \"NAME\",\n",
    "    \"REGION\",\n",
    "    \"DIVISION\",\n",
    "    \"POPESTIMATE2010\",\n",
    "    \"POPESTIMATE2011\",\n",
    "    \"POPESTIMATE2012\",\n",
    "    \"POPESTIMATE2013\",\n",
    "    \"POPESTIMATE2014\",\n",
    "    \"POPESTIMATE2015\",\n",
    "    \"POPESTIMATE2016\",\n",
    "    \"POPESTIMATE2017\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration of the resulting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-05 15:57:29 WARN  Utils:66 - Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\n",
      "+----------------+------+--------+---------------+---------------+---------------+\n",
      "|            NAME|REGION|DIVISION|POPESTIMATE2010|POPESTIMATE2011|POPESTIMATE2012|\n",
      "+----------------+------+--------+---------------+---------------+---------------+\n",
      "|   United States|     0|       0|      309338421|      311644280|      313993272|\n",
      "|Northeast Region|     1|       0|       55388349|       55642659|       55860261|\n",
      "|  Midwest Region|     2|       0|       66973360|       67141501|       67318295|\n",
      "+----------------+------+--------+---------------+---------------+---------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "statePopEst.drop(\"POPESTIMATE2013\" ,\"POPESTIMATE2014\", \"POPESTIMATE2015\", \"POPESTIMATE2016\", \"POPESTIMATE2017\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the census data of US states and validate that there are 50 states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "states: List[String] = List(Alabama, Alaska, Arizona, Arkansas, California, Colorado, Connecticut, Delaware, District of Columbia, Florida, Georgia, Hawaii, Idaho, Illinois, Indiana, Iowa, Kansas, Kentucky, Louisiana, Maine, Montana, Nebraska, Nevada, New Hampshire, New Jersey, New Mexico, New York, North Carolina, North Dakota, Ohio, Oklahoma, Oregon, Maryland, Massachusetts, Michigan, Minnesota, Mississippi, Missouri, Pennsylvania, Rhode Island, South Carolina, South Dakota, Tennessee, Texas, Utah, Vermont, Virginia, Washington, West Virginia, Wisconsin, Wyoming)\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val states = List(\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\", \"District of Columbia\", \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reducedStatePopEst: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [NAME: string, REGION: string ... 9 more fields]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val reducedStatePopEst = statePopEst.filter(col(\"NAME\").isin(states:_*))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states in census 2010-2017 dataset: 50"
     ]
    }
   ],
   "source": [
    "print(\"Number of states in census 2010-2017 dataset: \" + (reducedStatePopEst.count()-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- REGION: string (nullable = true)\n",
      " |-- DIVISION: string (nullable = true)\n",
      " |-- POPESTIMATE2010: string (nullable = true)\n",
      " |-- POPESTIMATE2011: string (nullable = true)\n",
      " |-- POPESTIMATE2012: string (nullable = true)\n",
      " |-- POPESTIMATE2013: string (nullable = true)\n",
      " |-- POPESTIMATE2014: string (nullable = true)\n",
      " |-- POPESTIMATE2015: string (nullable = true)\n",
      " |-- POPESTIMATE2016: string (nullable = true)\n",
      " |-- POPESTIMATE2017: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reducedStatePopEst.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population estimates are casted to Integers. \n",
    "\n",
    "### Each year receives a seperate row. This allows us to join on the year later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "popPerYear: org.apache.spark.sql.DataFrame = [State: string, Division: string ... 3 more fields]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val popPerYear = (2010 to 2017)\n",
    "    .map(year => reducedStatePopEst.select(\"NAME\", \"DIVISION\", \"REGION\", s\"POPESTIMATE${year}\")\n",
    "                .withColumnRenamed(s\"POPESTIMATE${year}\", \"Population\")\n",
    "                .withColumn(\"Year\", lit(year)))\n",
    "    .map(df => df.withColumn(\"Population\", $\"population\".cast(\"Int\")))\n",
    "    .reduce((df1, df2) => df1.union(df2))\n",
    "    .withColumnRenamed(\"NAME\",\"State\")\n",
    "    .withColumnRenamed(\"DIVISION\",\"Division\")\n",
    "    .withColumnRenamed(\"REGION\",\"Region\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resulting census dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- State: string (nullable = true)\n",
      " |-- Division: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Population: integer (nullable = true)\n",
      " |-- Year: integer (nullable = false)\n",
      "\n",
      "+--------------------+--------+------+----------+----+\n",
      "|               State|Division|Region|Population|Year|\n",
      "+--------------------+--------+------+----------+----+\n",
      "|             Alabama|       6|     3|   4785579|2010|\n",
      "|              Alaska|       9|     4|    714015|2010|\n",
      "|             Arizona|       8|     4|   6407002|2010|\n",
      "|            Arkansas|       7|     3|   2921737|2010|\n",
      "|          California|       9|     4|  37327690|2010|\n",
      "|            Colorado|       8|     4|   5048029|2010|\n",
      "|         Connecticut|       1|     1|   3580171|2010|\n",
      "|            Delaware|       5|     3|    899712|2010|\n",
      "|District of Columbia|       5|     3|    605040|2010|\n",
      "|             Florida|       5|     3|  18846461|2010|\n",
      "|             Georgia|       5|     3|   9712696|2010|\n",
      "|              Hawaii|       9|     4|   1363817|2010|\n",
      "|               Idaho|       8|     4|   1570912|2010|\n",
      "|            Illinois|       3|     2|  12841196|2010|\n",
      "|             Indiana|       3|     2|   6490029|2010|\n",
      "|                Iowa|       4|     2|   3050223|2010|\n",
      "|              Kansas|       4|     2|   2858403|2010|\n",
      "|            Kentucky|       6|     3|   4347948|2010|\n",
      "|           Louisiana|       7|     3|   4544871|2010|\n",
      "|               Maine|       1|     1|   1327568|2010|\n",
      "+--------------------+--------+------+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "popPerYear.printSchema\n",
    "popPerYear.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resulting death causes dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------------------+------+\n",
      "|Year|         Death Cause|               State|Deaths|\n",
      "+----+--------------------+--------------------+------+\n",
      "|2016|Accidents (uninte...|             Alabama|  2755|\n",
      "|2016|Accidents (uninte...|              Alaska|   439|\n",
      "|2016|Accidents (uninte...|             Arizona|  4010|\n",
      "|2016|Accidents (uninte...|            Arkansas|  1604|\n",
      "|2016|Accidents (uninte...|          California| 13213|\n",
      "|2016|Accidents (uninte...|            Colorado|  2880|\n",
      "|2016|Accidents (uninte...|         Connecticut|  1978|\n",
      "|2016|Accidents (uninte...|            Delaware|   516|\n",
      "|2016|Accidents (uninte...|District of Columbia|   401|\n",
      "|2016|Accidents (uninte...|             Florida| 12561|\n",
      "|2016|Accidents (uninte...|             Georgia|  4701|\n",
      "|2016|Accidents (uninte...|              Hawaii|   577|\n",
      "|2016|Accidents (uninte...|               Idaho|   849|\n",
      "|2016|Accidents (uninte...|            Illinois|  5508|\n",
      "|2016|Accidents (uninte...|             Indiana|  3496|\n",
      "|2016|Accidents (uninte...|                Iowa|  1608|\n",
      "|2016|Accidents (uninte...|              Kansas|  1444|\n",
      "|2016|Accidents (uninte...|            Kentucky|  3194|\n",
      "|2016|Accidents (uninte...|           Louisiana|  2710|\n",
      "|2016|Accidents (uninte...|               Maine|   909|\n",
      "+----+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deathCauses.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join on year and  state to receive death causes per state and year in relation to the states population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deathCausesPerStateYear: org.apache.spark.sql.DataFrame = [Year: int, State: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val deathCausesPerStateYear = popPerYear.join(deathCauses, Seq(\"Year\",\"State\"), \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+--------+------+----------+--------------------+------+\n",
      "|Year|               State|Division|Region|Population|         Death Cause|Deaths|\n",
      "+----+--------------------+--------+------+----------+--------------------+------+\n",
      "|2016|             Alabama|       6|     3|   4860545|Accidents (uninte...|  2755|\n",
      "|2016|              Alaska|       9|     4|    741522|Accidents (uninte...|   439|\n",
      "|2016|             Arizona|       8|     4|   6908642|Accidents (uninte...|  4010|\n",
      "|2016|            Arkansas|       7|     3|   2988231|Accidents (uninte...|  1604|\n",
      "|2016|          California|       9|     4|  39296476|Accidents (uninte...| 13213|\n",
      "|2016|            Colorado|       8|     4|   5530105|Accidents (uninte...|  2880|\n",
      "|2016|         Connecticut|       1|     1|   3587685|Accidents (uninte...|  1978|\n",
      "|2016|            Delaware|       5|     3|    952698|Accidents (uninte...|   516|\n",
      "|2016|District of Columbia|       5|     3|    684336|Accidents (uninte...|   401|\n",
      "|2016|             Florida|       5|     3|  20656589|Accidents (uninte...| 12561|\n",
      "|2016|             Georgia|       5|     3|  10313620|Accidents (uninte...|  4701|\n",
      "|2016|              Hawaii|       9|     4|   1428683|Accidents (uninte...|   577|\n",
      "|2016|               Idaho|       8|     4|   1680026|Accidents (uninte...|   849|\n",
      "|2016|            Illinois|       3|     2|  12835726|Accidents (uninte...|  5508|\n",
      "|2016|             Indiana|       3|     2|   6634007|Accidents (uninte...|  3496|\n",
      "|2016|                Iowa|       4|     2|   3130869|Accidents (uninte...|  1608|\n",
      "|2016|              Kansas|       4|     2|   2907731|Accidents (uninte...|  1444|\n",
      "|2016|            Kentucky|       6|     3|   4436113|Accidents (uninte...|  3194|\n",
      "|2016|           Louisiana|       7|     3|   4686157|Accidents (uninte...|  2710|\n",
      "|2016|               Maine|       1|     1|   1330232|Accidents (uninte...|   909|\n",
      "+----+--------------------+--------+------+----------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deathCausesPerStateYear.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding states with the highest amount of deaths per resident:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deathRatio: org.apache.spark.sql.DataFrame = [State: string, Year: int ... 1 more field]\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deathCausesPerStateYear.createOrReplaceTempView(\"deathCausesPerStateYear\")\n",
    "\n",
    "val deathRatio = spark\n",
    "    .sql(\"SELECT State, Year, Round(sum(deaths)/sum(population)*100,6) AS DeathRatio \" +\n",
    "         \"FROM deathCausesPerStateYear \" +\n",
    "         \"GROUP BY State, Year \" +\n",
    "         \"ORDER BY DeathRatio desc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or finding the states with the highest amount of suicides per resident:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----+----------+\n",
      "|        State|Year|DeathRatio|\n",
      "+-------------+----+----------+\n",
      "|West Virginia|2016|  0.195938|\n",
      "|West Virginia|2015|  0.194881|\n",
      "|West Virginia|2014|  0.189767|\n",
      "|West Virginia|2011|  0.187323|\n",
      "|West Virginia|2012|  0.186864|\n",
      "|West Virginia|2013|  0.185908|\n",
      "|West Virginia|2010|  0.182557|\n",
      "|        Maine|2015|  0.171571|\n",
      "|  Mississippi|2016|  0.171433|\n",
      "|     Arkansas|2015|  0.171301|\n",
      "|  Mississippi|2015|  0.171008|\n",
      "|     Arkansas|2016|  0.170879|\n",
      "|     Kentucky|2016|   0.17077|\n",
      "|      Alabama|2016|  0.170654|\n",
      "|      Alabama|2015|  0.169485|\n",
      "|        Maine|2016|  0.168118|\n",
      "|     Kentucky|2015|  0.166909|\n",
      "|     Arkansas|2014|  0.164491|\n",
      "|     Arkansas|2013|  0.164267|\n",
      "|     Oklahoma|2015|  0.163691|\n",
      "+-------------+----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "deathRatio.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding states with the lowest and highest suicide rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "highestSuicideRatio: org.apache.spark.sql.DataFrame = [State: string, Year: int ... 1 more field]\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deathCausesPerStateYear\n",
    "    .filter($\"Death Cause\".contains(\"suicide\"))\n",
    "    .createOrReplaceTempView(\"suicidesPerStateYear\")\n",
    "\n",
    "val highestSuicideRatio = spark\n",
    "    .sql(\"SELECT State, Year, Round(sum(deaths)/sum(population)*100,4) AS SuicideRatio \" +\n",
    "         \"FROM suicidesPerStateYear \" +\n",
    "         \"GROUP BY State, Year \" +\n",
    "         \"ORDER BY SuicideRatio desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------------+\n",
      "|     State|Year|SuicideRatio|\n",
      "+----------+----+------------+\n",
      "|   Wyoming|2012|      0.0297|\n",
      "|    Alaska|2015|      0.0272|\n",
      "|   Wyoming|2015|      0.0268|\n",
      "|   Montana|2015|      0.0265|\n",
      "|    Alaska|2016|       0.026|\n",
      "|   Montana|2016|      0.0257|\n",
      "|   Montana|2014|      0.0246|\n",
      "|   Wyoming|2016|      0.0246|\n",
      "|   Montana|2013|       0.024|\n",
      "|New Mexico|2015|       0.024|\n",
      "|   Wyoming|2011|      0.0233|\n",
      "|   Montana|2011|      0.0233|\n",
      "|   Wyoming|2010|      0.0232|\n",
      "|   Montana|2012|      0.0232|\n",
      "|    Alaska|2013|      0.0232|\n",
      "|    Alaska|2012|       0.023|\n",
      "|    Alaska|2010|       0.023|\n",
      "|   Montana|2010|      0.0229|\n",
      "|    Alaska|2014|      0.0227|\n",
      "|New Mexico|2016|      0.0226|\n",
      "+----------+----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "highestSuicideRatio.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lowestSuicideRatio: org.apache.spark.sql.DataFrame = [State: string, Year: int ... 1 more field]\n"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val lowestSuicideRatio = spark\n",
    "    .sql(\"SELECT State, Year, Round(sum(deaths)/sum(population)*100,4) AS SuicideRatio \" +\n",
    "         \"FROM suicidesPerStateYear \" +\n",
    "         \"GROUP BY State, Year \" +\n",
    "         \"ORDER BY SuicideRatio asc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+------------+\n",
      "|               State|Year|SuicideRatio|\n",
      "+--------------------+----+------------+\n",
      "|District of Columbia|2015|      0.0051|\n",
      "|District of Columbia|2013|      0.0058|\n",
      "|District of Columbia|2012|      0.0058|\n",
      "|District of Columbia|2016|      0.0058|\n",
      "|District of Columbia|2011|       0.006|\n",
      "|District of Columbia|2010|      0.0068|\n",
      "|          New Jersey|2012|      0.0077|\n",
      "|          New Jersey|2016|      0.0077|\n",
      "|          New Jersey|2011|      0.0078|\n",
      "|District of Columbia|2014|      0.0079|\n",
      "|            New York|2010|       0.008|\n",
      "|          New Jersey|2010|      0.0082|\n",
      "|            New York|2015|      0.0083|\n",
      "|       Massachusetts|2013|      0.0085|\n",
      "|            New York|2016|      0.0085|\n",
      "|          New Jersey|2013|      0.0085|\n",
      "|            New York|2011|      0.0085|\n",
      "|            New York|2014|      0.0086|\n",
      "|            New York|2013|      0.0086|\n",
      "|            New York|2012|      0.0087|\n",
      "+--------------------+----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lowestSuicideRatio.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
